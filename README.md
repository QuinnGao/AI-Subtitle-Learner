# è§†é¢‘å­—å¹•å¤„ç† API

è¿™æ˜¯ä¸€ä¸ªåŸºäº FastAPI æ„å»ºçš„è§†é¢‘å­—å¹•å¤„ç†åç«¯æœåŠ¡ï¼Œæä¾›è§†é¢‘è½¬å½•ã€å­—å¹•å¤„ç†ã€è§†é¢‘åˆæˆç­‰åŠŸèƒ½ã€‚

## æŠ€æœ¯æ ˆ

- **FastAPI**: ç°ä»£ã€å¿«é€Ÿçš„ Web æ¡†æ¶ï¼Œç”¨äºæ„å»º API
- **Python 3.12**: ç¼–ç¨‹è¯­è¨€
- **Uvicorn**: ASGI æœåŠ¡å™¨
- **Pydantic**: æ•°æ®éªŒè¯å’Œè®¾ç½®ç®¡ç†

## é¡¹ç›®ç‰¹æ€§

- ğŸš€ é«˜æ€§èƒ½å¼‚æ­¥ API
- ğŸ“ è‡ªåŠ¨ç”Ÿæˆ API æ–‡æ¡£ï¼ˆSwagger UI å’Œ ReDocï¼‰
- ğŸ”’ ç±»å‹æç¤ºå’Œæ•°æ®éªŒè¯
- ğŸ¬ è§†é¢‘è½¬å½•ï¼šæ”¯æŒå¤šç§ ASR æ¨¡å‹ï¼ˆWhisperã€Faster Whisper ç­‰ï¼‰
- ğŸŒ å­—å¹•ç¿»è¯‘ï¼šæ”¯æŒå¤šç§ç¿»è¯‘æœåŠ¡ï¼ˆOpenAIã€DeepLXã€Bingã€Googleï¼‰
- âœ‚ï¸ å­—å¹•å¤„ç†ï¼šè‡ªåŠ¨åˆ†å‰²ã€ä¼˜åŒ–ã€ç¿»è¯‘
- ğŸ¥ è§†é¢‘åˆæˆï¼šå°†å­—å¹•åˆæˆåˆ°è§†é¢‘ä¸­
- ğŸ“¦ æ‰¹é‡å¤„ç†ï¼šæ”¯æŒæ‰¹é‡å¤„ç†å¤šä¸ªæ–‡ä»¶
- ğŸ”„ å¼‚æ­¥ä»»åŠ¡ï¼šåå°ä»»åŠ¡å¤„ç†ï¼Œæ”¯æŒè¿›åº¦æŸ¥è¯¢

## å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒè¦æ±‚

- Python 3.12
- uvï¼ˆç°ä»£ Python åŒ…ç®¡ç†å™¨ï¼‰

### 2. å®‰è£… uv

```bash
# macOS/Linux
curl -LsSf https://astral.sh/uv/install.sh | sh

# æˆ–ä½¿ç”¨ pip
pip install uv

# æˆ–ä½¿ç”¨ Homebrew (macOS)
brew install uv
```

### 3. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ

```bash
# ä½¿ç”¨ uv åˆ›å»ºè™šæ‹Ÿç¯å¢ƒï¼ˆé»˜è®¤åˆ›å»º .venv ç›®å½•ï¼‰
# æŒ‡å®š Python 3.12 ç‰ˆæœ¬
uv venv --python 3.12

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
# macOS/Linux:
source .venv/bin/activate
# Windows:
.venv\Scripts\activate
```

### 4. å®‰è£…ä¾èµ–

```bash
# ä½¿ç”¨ uv å®‰è£…ä¾èµ–ï¼ˆæ¨èï¼Œé€Ÿåº¦æ›´å¿«ï¼‰
uv pip install fastapi uvicorn[standard]
```

æˆ–è€…åˆ›å»º `requirements.txt` æ–‡ä»¶ï¼š

```txt
fastapi>=0.104.1
uvicorn[standard]>=0.24.0
pydantic>=2.5.0
pydantic-settings>=2.1.0
python-multipart>=0.0.6
```

ç„¶åå®‰è£…ï¼š

```bash
uv pip install -r requirements.txt
```

**æç¤º**ï¼šä½¿ç”¨ `uv` æ—¶ï¼Œä¹Ÿå¯ä»¥ä¸æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼Œç›´æ¥ä½¿ç”¨ `uv run` è¿è¡Œå‘½ä»¤ï¼š

```bash
# æ— éœ€æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼Œç›´æ¥è¿è¡Œ
uv run uvicorn app.main:app --reload
```

### 6. è¿è¡Œåº”ç”¨

#### æ–¹æ³• 1ï¼šä½¿ç”¨ uv runï¼ˆæ¨èï¼‰

```bash
# ç›´æ¥è¿è¡Œï¼Œæ— éœ€æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
uv run uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

#### æ–¹æ³• 2ï¼šä½¿ç”¨è¿è¡Œè„šæœ¬

```bash
# ä½¿ç”¨æä¾›çš„è¿è¡Œè„šæœ¬
./run.sh
```

#### æ–¹æ³• 3ï¼šæ¿€æ´»è™šæ‹Ÿç¯å¢ƒåè¿è¡Œ

```bash
# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
source .venv/bin/activate  # macOS/Linux
# æˆ–
.venv\Scripts\activate  # Windows

# è¿è¡Œåº”ç”¨
uvicorn app.main:app --host 0.0.0.0 --port 8000 --reload
```

åº”ç”¨å¯åŠ¨åï¼Œè®¿é—®ï¼š
- API æ–‡æ¡£ï¼šhttp://localhost:8000/docs
- å¥åº·æ£€æŸ¥ï¼šhttp://localhost:8000/health

### 5. åˆ›å»ºé¡¹ç›®ç»“æ„

```
.
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py          # FastAPI åº”ç”¨å…¥å£
â”‚   â”œâ”€â”€ models/          # æ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ routers/         # API è·¯ç”±
â”‚   â”œâ”€â”€ schemas/         # Pydantic æ¨¡å¼
â”‚   â””â”€â”€ services/        # ä¸šåŠ¡é€»è¾‘
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env                 # ç¯å¢ƒå˜é‡ï¼ˆå¯é€‰ï¼‰
â””â”€â”€ README.md
```

### 6. å®‰è£…é¡¹ç›®ä¾èµ–

é¡¹ç›®å·²ç»åŒ…å«äº†å®Œæ•´çš„ä»£ç ç»“æ„ï¼Œç›´æ¥å®‰è£…ä¾èµ–å³å¯ï¼š

```bash
# å®‰è£… FastAPI å’Œç›¸å…³ä¾èµ–
uv pip install fastapi uvicorn[standard] pydantic pydantic-settings python-multipart

# å®‰è£…é¡¹ç›®æ‰€éœ€çš„å…¶ä»–ä¾èµ–ï¼ˆæ ¹æ® core æ¨¡å—çš„éœ€æ±‚ï¼‰
# ä¾‹å¦‚ï¼šfaster-whisper, openai, requests ç­‰
```

### 7. é…ç½®ç¯å¢ƒå˜é‡

åˆ›å»º `.env` æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰ï¼š

```env
# åº”ç”¨é…ç½®
DEBUG=False
LOG_LEVEL=INFO
WORK_DIR=./workspace
MODEL_DIR=./models

# LLM é…ç½®ï¼ˆå¯é€‰ï¼Œæ”¯æŒå¤šç§ç¯å¢ƒå˜é‡åç§°ï¼‰
# æ–°æ ¼å¼ï¼ˆæ¨èï¼‰
LLM_API_BASE=https://api.openai.com/v1
LLM_API_KEY=your-api-key
LLM_MODEL=gpt-4o-mini

# å…¼å®¹æ—§æ ¼å¼ï¼ˆå¯é€‰ï¼‰
OPENAI_API_BASE=https://api.openai.com/v1
OPENAI_API_KEY=your-api-key
OPENAI_MODEL=gpt-4o-mini

# ç¿»è¯‘æœåŠ¡é…ç½®ï¼ˆå¯é€‰ï¼‰
DEEPLX_ENDPOINT=http://localhost:1188
```

### 8. æå‰ä¸‹è½½ WhisperX æ¨¡å‹ï¼ˆå¯é€‰ä½†æ¨èï¼‰

å¦‚æœä½¿ç”¨ WhisperX è¿›è¡Œè½¬å½•ï¼Œå»ºè®®æå‰ä¸‹è½½æ¨¡å‹ä»¥é¿å…é¦–æ¬¡ä½¿ç”¨æ—¶çš„å»¶è¿Ÿã€‚

#### æ–¹æ³• 1: ä½¿ç”¨ Shell è„šæœ¬ä¸‹è½½ï¼ˆæ¨èï¼‰

ä½¿ç”¨ Git ç›´æ¥ä¸‹è½½æ¨¡å‹æ–‡ä»¶åˆ° `models/whisperx/` ç›®å½•ï¼š

```bash
# ä¸‹è½½æ‰€æœ‰ WhisperX æ¨¡å‹ï¼ˆWhisperã€Silero VADã€wav2vec2ï¼‰
./scripts/download_whisperx_models.sh

# æˆ–ä½¿ç”¨ bash
bash scripts/download_whisperx_models.sh
```

è„šæœ¬ä¼šè‡ªåŠ¨ï¼š
- åˆ›å»º `models/whisperx/` ç›®å½•
- ä¸‹è½½ `whisper-large-v3` æ¨¡å‹
- ä¸‹è½½ `silero-vad` æ¨¡å‹
- ä¸‹è½½ `wav2vec2` æ¨¡å‹
- å¦‚æœæ¨¡å‹å·²å­˜åœ¨ï¼Œä¼šè·³è¿‡ä¸‹è½½

#### æ–¹æ³• 2: ä½¿ç”¨ Python è„šæœ¬ä¸‹è½½

ä½¿ç”¨ Python è„šæœ¬é€šè¿‡ WhisperX API ä¸‹è½½æ¨¡å‹ï¼š

```bash
# ä½¿ç”¨ uv æ‰§è¡Œï¼ˆæ¨èï¼‰
uv run python scripts/download_whisperx_models.py

# æˆ–ä½¿ç”¨ python
python scripts/download_whisperx_models.py

# æˆ–ä½¿ç”¨ python3
python3 scripts/download_whisperx_models.py
```

#### é«˜çº§é€‰é¡¹ï¼ˆPython è„šæœ¬ï¼‰

```bash
# ä¸‹è½½æŒ‡å®šæ¨¡å‹
uv run python scripts/download_whisperx_models.py --model large-v2

# æŒ‡å®šè®¾å¤‡ï¼ˆcuda/cpu/autoï¼‰
uv run python scripts/download_whisperx_models.py --model large-v3 --device cuda

# åªä¸‹è½½ Whisper æ¨¡å‹ï¼Œè·³è¿‡å¯¹é½æ¨¡å‹
uv run python scripts/download_whisperx_models.py --model large-v3 --skip-align

# ä¸‹è½½æŒ‡å®šè¯­è¨€çš„å¯¹é½æ¨¡å‹
uv run python scripts/download_whisperx_models.py --model large-v3 --languages en zh ja ko

# æŒ‡å®šè‡ªå®šä¹‰æ¨¡å‹ç›®å½•
uv run python scripts/download_whisperx_models.py --model-dir /path/to/models
```

### 9. è¿è¡Œåº”ç”¨

```bash
# å¼€å‘æ¨¡å¼ï¼ˆè‡ªåŠ¨é‡è½½ï¼‰
uvicorn app.main:app --reload

# ç”Ÿäº§æ¨¡å¼
uvicorn app.main:app --host 0.0.0.0 --port 8000
```

åº”ç”¨å°†åœ¨ `http://localhost:8000` å¯åŠ¨ã€‚

## API æ–‡æ¡£

å¯åŠ¨åº”ç”¨åï¼Œå¯ä»¥è®¿é—®ä»¥ä¸‹åœ°å€æŸ¥çœ‹è‡ªåŠ¨ç”Ÿæˆçš„ API æ–‡æ¡£ï¼š

- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

## API ç«¯ç‚¹

### å¥åº·æ£€æŸ¥
- `GET /health` - å¥åº·æ£€æŸ¥

### è½¬å½•ç›¸å…³
- `POST /api/v1/transcribe` - åˆ›å»ºè½¬å½•ä»»åŠ¡
- `GET /api/v1/transcribe/{task_id}` - æŸ¥è¯¢è½¬å½•ä»»åŠ¡çŠ¶æ€
- `GET /api/v1/transcribe/{task_id}/download` - ä¸‹è½½è½¬å½•ç»“æœ

### å­—å¹•å¤„ç†
- `POST /api/v1/subtitle` - åˆ›å»ºå­—å¹•å¤„ç†ä»»åŠ¡
- `GET /api/v1/subtitle/{task_id}` - æŸ¥è¯¢å­—å¹•å¤„ç†ä»»åŠ¡çŠ¶æ€
- `GET /api/v1/subtitle/{task_id}/download` - ä¸‹è½½å­—å¹•å¤„ç†ç»“æœ

### è§†é¢‘åˆæˆ
- `POST /api/v1/synthesis` - åˆ›å»ºè§†é¢‘åˆæˆä»»åŠ¡
- `GET /api/v1/synthesis/{task_id}` - æŸ¥è¯¢è§†é¢‘åˆæˆä»»åŠ¡çŠ¶æ€
- `GET /api/v1/synthesis/{task_id}/download` - ä¸‹è½½åˆæˆåçš„è§†é¢‘

### è§†é¢‘ä¿¡æ¯
- `GET /api/v1/video/info?file_path=...` - è·å–è§†é¢‘ä¿¡æ¯

### æ‰¹é‡å¤„ç†
- `POST /api/v1/batch` - åˆ›å»ºæ‰¹é‡å¤„ç†ä»»åŠ¡
- `GET /api/v1/batch/{task_id}` - æŸ¥è¯¢æ‰¹é‡å¤„ç†ä»»åŠ¡çŠ¶æ€

## é¡¹ç›®ç»“æ„è¯´æ˜

```
.
â”œâ”€â”€ app/                      # FastAPI åº”ç”¨ä¸»ç›®å½•
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py              # FastAPI åº”ç”¨å…¥å£å’Œè·¯ç”±æ³¨å†Œ
â”‚   â”œâ”€â”€ config.py            # åº”ç”¨é…ç½®
â”‚   â”œâ”€â”€ routers/             # API è·¯ç”±æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ health.py        # å¥åº·æ£€æŸ¥è·¯ç”±
â”‚   â”‚   â”œâ”€â”€ transcribe.py    # è½¬å½•ç›¸å…³è·¯ç”±
â”‚   â”‚   â”œâ”€â”€ subtitle.py      # å­—å¹•å¤„ç†è·¯ç”±
â”‚   â”‚   â”œâ”€â”€ synthesis.py     # è§†é¢‘åˆæˆè·¯ç”±
â”‚   â”‚   â”œâ”€â”€ video.py         # è§†é¢‘ä¿¡æ¯è·¯ç”±
â”‚   â”‚   â””â”€â”€ batch.py         # æ‰¹é‡å¤„ç†è·¯ç”±
â”‚   â”œâ”€â”€ schemas/             # Pydantic æ•°æ®éªŒè¯æ¨¡å¼
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ common.py        # é€šç”¨æ•°æ®æ¨¡å‹ï¼ˆVideoInfo, TaskResponseç­‰ï¼‰
â”‚   â”‚   â”œâ”€â”€ transcribe.py    # è½¬å½•ç›¸å…³æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ subtitle.py      # å­—å¹•å¤„ç†æ¨¡å‹
â”‚   â”‚   â”œâ”€â”€ synthesis.py     # è§†é¢‘åˆæˆæ¨¡å‹
â”‚   â”‚   â””â”€â”€ batch.py         # æ‰¹é‡å¤„ç†æ¨¡å‹
â”‚   â”œâ”€â”€ services/            # ä¸šåŠ¡é€»è¾‘æœåŠ¡å±‚
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ task_manager.py  # ä»»åŠ¡ç®¡ç†å™¨
â”‚   â”‚   â”œâ”€â”€ transcribe_service.py    # è½¬å½•æœåŠ¡
â”‚   â”‚   â”œâ”€â”€ subtitle_service.py      # å­—å¹•å¤„ç†æœåŠ¡
â”‚   â”‚   â”œâ”€â”€ synthesis_service.py     # è§†é¢‘åˆæˆæœåŠ¡
â”‚   â”‚   â”œâ”€â”€ video_service.py         # è§†é¢‘ä¿¡æ¯æœåŠ¡
â”‚   â”‚   â””â”€â”€ batch_service.py         # æ‰¹é‡å¤„ç†æœåŠ¡
â”‚   â””â”€â”€ core/                # æ ¸å¿ƒä¸šåŠ¡é€»è¾‘ï¼ˆä¿ç•™åŸæœ‰ç»“æ„ï¼‰
â”‚       â”œâ”€â”€ asr/             # è¯­éŸ³è¯†åˆ«æ¨¡å—
â”‚       â”œâ”€â”€ translate/       # ç¿»è¯‘æ¨¡å—
â”‚       â”œâ”€â”€ split/           # å­—å¹•åˆ†å‰²æ¨¡å—
â”‚       â”œâ”€â”€ optimize/       # å­—å¹•ä¼˜åŒ–æ¨¡å—
â”‚       â”œâ”€â”€ tts/             # æ–‡æœ¬è½¬è¯­éŸ³æ¨¡å—
â”‚       â”œâ”€â”€ llm/             # å¤§è¯­è¨€æ¨¡å‹æ¨¡å—
â”‚       â”œâ”€â”€ utils/           # å·¥å…·å‡½æ•°
â”‚       â”œâ”€â”€ entities.py      # å®ä½“å®šä¹‰
â”‚       â””â”€â”€ task_factory.py  # ä»»åŠ¡å·¥å‚
â”œâ”€â”€ requirements.txt        # Python ä¾èµ–
â”œâ”€â”€ .env                    # ç¯å¢ƒå˜é‡é…ç½®
â””â”€â”€ README.md               # é¡¹ç›®è¯´æ˜æ–‡æ¡£
```

## ä½¿ç”¨ç¤ºä¾‹

### åˆ›å»ºè½¬å½•ä»»åŠ¡

```python
import requests

# åˆ›å»ºè½¬å½•ä»»åŠ¡
response = requests.post("http://localhost:8000/api/v1/transcribe", json={
    "file_path": "/path/to/video.mp4",
    "config": {
        "transcribe_model": "faster_whisper",
        "transcribe_language": "zh",
        "output_format": "srt"
    }
})

task_id = response.json()["task_id"]

# æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
status_response = requests.get(f"http://localhost:8000/api/v1/transcribe/{task_id}")
print(status_response.json())

# ä¸‹è½½ç»“æœï¼ˆä»»åŠ¡å®Œæˆåï¼‰
if status_response.json()["status"] == "completed":
    download_response = requests.get(
        f"http://localhost:8000/api/v1/transcribe/{task_id}/download"
    )
    with open("output.srt", "wb") as f:
        f.write(download_response.content)
```

### åˆ›å»ºå­—å¹•å¤„ç†ä»»åŠ¡

```python
response = requests.post("http://localhost:8000/api/v1/subtitle", json={
    "subtitle_path": "/path/to/subtitle.srt",
    "config": {
        "need_translate": True,
        "translator_service": "openai",
        "target_language": "en",
        "need_optimize": True,
        "need_split": True
    }
})
```

## å¼€å‘æŒ‡å—

### æ·»åŠ æ–°çš„è·¯ç”±

1. åœ¨ `app/routers/` ç›®å½•ä¸‹åˆ›å»ºæ–°çš„è·¯ç”±æ–‡ä»¶
2. ä½¿ç”¨ `APIRouter` åˆ›å»ºè·¯ç”±å®ä¾‹
3. åœ¨ `app/main.py` ä¸­æ³¨å†Œè·¯ç”±

### æ·»åŠ æ–°çš„æœåŠ¡

1. åœ¨ `app/services/` ç›®å½•ä¸‹åˆ›å»ºæ–°çš„æœåŠ¡æ–‡ä»¶
2. å®ç°ä¸šåŠ¡é€»è¾‘ï¼Œè°ƒç”¨ `core` æ¨¡å—ä¸­çš„åŠŸèƒ½
3. åœ¨è·¯ç”±ä¸­ä½¿ç”¨æœåŠ¡

### ç¯å¢ƒå˜é‡é…ç½®

ä½¿ç”¨ `python-dotenv` ç®¡ç†ç¯å¢ƒå˜é‡ï¼š

```bash
uv pip install python-dotenv
```

åˆ›å»º `.env` æ–‡ä»¶ï¼š

```env
DATABASE_URL=postgresql://user:password@localhost/dbname
SECRET_KEY=your-secret-key
DEBUG=True
```

åœ¨ä»£ç ä¸­ä½¿ç”¨ï¼š

```python
from dotenv import load_dotenv
import os

load_dotenv()
database_url = os.getenv("DATABASE_URL")
```

## æµ‹è¯•

### åœ¨ Docker å®¹å™¨ä¸­è¿è¡Œæµ‹è¯•ï¼ˆæ¨èï¼‰

é¡¹ç›®æä¾›äº† Docker Compose é…ç½®æ¥è¿è¡Œæµ‹è¯•ï¼Œç¡®ä¿æµ‹è¯•ç¯å¢ƒä¸ç”Ÿäº§ç¯å¢ƒä¸€è‡´ã€‚

#### ä½¿ç”¨è„šæœ¬è¿è¡Œ

**Linux/macOS:**
```bash
# è¿è¡Œå­—å¹•æ¥å£æµ‹è¯•
./scripts/run-tests.sh subtitle

# è¿è¡Œæ‰€æœ‰æµ‹è¯•
./scripts/run-tests.sh all

# è¿è¡Œæµ‹è¯•å¹¶ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
./scripts/run-tests.sh coverage
```

**Windows (PowerShell):**
```powershell
# è¿è¡Œå­—å¹•æ¥å£æµ‹è¯•
.\scripts\run-tests.ps1 subtitle

# è¿è¡Œæ‰€æœ‰æµ‹è¯•
.\scripts\run-tests.ps1 all

# è¿è¡Œæµ‹è¯•å¹¶ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
.\scripts\run-tests.ps1 coverage
```

#### ä½¿ç”¨ Makefile

```bash
# è¿è¡Œå­—å¹•æ¥å£æµ‹è¯•ï¼ˆé»˜è®¤ï¼‰
make test

# è¿è¡Œæ‰€æœ‰æµ‹è¯•
make test-all

# è¿è¡Œæµ‹è¯•å¹¶ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
make test-coverage

# æ¸…ç†æµ‹è¯•ç»“æœ
make clean
```

#### ç›´æ¥ä½¿ç”¨ Docker Compose

```bash
# è¿è¡Œå­—å¹•æ¥å£æµ‹è¯•
docker-compose -f docker-compose.test.yml run --rm test

# è¿è¡Œæ‰€æœ‰æµ‹è¯•
docker-compose -f docker-compose.test.yml run --rm test-all

# è¿è¡Œæµ‹è¯•å¹¶ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
docker-compose -f docker-compose.test.yml run --rm test-coverage
```

### æœ¬åœ°è¿è¡Œæµ‹è¯•ï¼ˆä¸ä½¿ç”¨ Dockerï¼‰

```bash
# å®‰è£…æµ‹è¯•ä¾èµ–
uv pip install pytest pytest-asyncio pytest-cov

# è¿è¡Œæ‰€æœ‰æµ‹è¯•
pytest

# è¿è¡Œå­—å¹•æ¥å£æµ‹è¯•
pytest tests/test_subtitle.py -v

# æˆ–ä½¿ç”¨ uv runï¼ˆæ— éœ€æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼‰
uv run pytest tests/test_subtitle.py -v

# æŸ¥çœ‹æµ‹è¯•è¦†ç›–ç‡
pytest --cov=app --cov-report=html tests/
```

æ›´å¤šæµ‹è¯•è¯´æ˜è¯·å‚è€ƒ [tests/README.md](tests/README.md)

## éƒ¨ç½²

### ä½¿ç”¨ Docker Composeï¼ˆæ¨èï¼‰

é¡¹ç›®å·²åŒ…å«å®Œæ•´çš„ Docker Compose é…ç½®ï¼Œå¯ä»¥ä¸€é”®å¯åŠ¨ï¼š

```bash
# 1. å¤åˆ¶ç¯å¢ƒå˜é‡æ–‡ä»¶ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
cp .env.example .env
# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œé…ç½®å¿…è¦çš„ç¯å¢ƒå˜é‡

# 2. æ„å»ºå¹¶å¯åŠ¨æœåŠ¡
docker-compose up -d

# 3. æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f

# 4. åœæ­¢æœåŠ¡
docker-compose down
```

#### Docker Compose é…ç½®è¯´æ˜

- **ç«¯å£æ˜ å°„**: `8000:8000` - API æœåŠ¡ç«¯å£
- **æ•°æ®å·æŒ‚è½½**:
  - `./workspace:/app/workspace` - å·¥ä½œç›®å½•ï¼ˆå¤„ç†ä¸­çš„æ–‡ä»¶ï¼‰
  - `./models:/app/models` - æ¨¡å‹ç›®å½•ï¼ˆAI æ¨¡å‹ï¼‰
  - `./logs:/app/logs` - æ—¥å¿—ç›®å½•
  - `./input:/app/input:ro` - è¾“å…¥æ–‡ä»¶ç›®å½•ï¼ˆåªè¯»ï¼‰
  - `./output:/app/output` - è¾“å‡ºæ–‡ä»¶ç›®å½•

#### ç¯å¢ƒå˜é‡é…ç½®

åˆ›å»º `.env` æ–‡ä»¶å¹¶é…ç½®ä»¥ä¸‹å˜é‡ï¼š

```env
# åº”ç”¨é…ç½®
DEBUG=False
LOG_LEVEL=INFO

# LLM é…ç½®ï¼ˆå¯é€‰ï¼Œæ”¯æŒå¤šç§ç¯å¢ƒå˜é‡åç§°ï¼‰
# æ–°æ ¼å¼ï¼ˆæ¨èï¼‰
LLM_API_BASE=https://api.openai.com/v1
LLM_API_KEY=your-api-key-here
LLM_MODEL=gpt-4o-mini

# å…¼å®¹æ—§æ ¼å¼ï¼ˆå¯é€‰ï¼‰
OPENAI_API_BASE=https://api.openai.com/v1
OPENAI_API_KEY=your-api-key-here
OPENAI_MODEL=gpt-4o-mini

# ç¿»è¯‘æœåŠ¡é…ç½®ï¼ˆå¯é€‰ï¼‰
DEEPLX_ENDPOINT=http://localhost:1188
```

### ä½¿ç”¨ Dockerï¼ˆå•ç‹¬æ„å»ºï¼‰

å¦‚æœåªéœ€è¦æ„å»ºå•ä¸ªé•œåƒï¼š

```bash
# æ„å»ºé•œåƒ
docker build -t video-subtitle-api .

# è¿è¡Œå®¹å™¨
docker run -d \
  --name video-subtitle-api \
  -p 8000:8000 \
  -v $(pwd)/workspace:/app/workspace \
  -v $(pwd)/models:/app/models \
  -v $(pwd)/logs:/app/logs \
  --env-file .env \
  video-subtitle-api
```

### GPU æ”¯æŒ

å¦‚æœç³»ç»Ÿæœ‰ NVIDIA GPU å¹¶å®‰è£…äº† nvidia-dockerï¼Œå¯ä»¥ä½¿ç”¨ GPU ç‰ˆæœ¬ï¼š

```bash
# ä½¿ç”¨ GPU ç‰ˆæœ¬çš„ Docker Compose
docker-compose -f docker-compose.gpu.yml up -d

# æˆ–è€…å•ç‹¬æ„å»º GPU é•œåƒ
docker build -f Dockerfile.gpu -t video-subtitle-api-gpu .
docker run -d \
  --name video-subtitle-api-gpu \
  --gpus all \
  -p 8000:8000 \
  -v $(pwd)/workspace:/app/workspace \
  -v $(pwd)/models:/app/models \
  -v $(pwd)/logs:/app/logs \
  --env-file .env \
  video-subtitle-api-gpu
```

**æ³¨æ„**: GPU ç‰ˆæœ¬éœ€è¦ï¼š
- NVIDIA GPU é©±åŠ¨
- nvidia-docker2 æˆ– Docker with GPU support
- CUDA 12.1+ è¿è¡Œæ—¶

## å¸¸ç”¨å‘½ä»¤

### å¼€å‘ç¯å¢ƒ

```bash
# å¯åŠ¨å¼€å‘æœåŠ¡å™¨
uvicorn app.main:app --reload
# æˆ–ä½¿ç”¨ uv runï¼ˆæ— éœ€æ¿€æ´»è™šæ‹Ÿç¯å¢ƒï¼‰
uv run uvicorn app.main:app --reload

# æ£€æŸ¥ä»£ç æ ¼å¼ï¼ˆéœ€è¦ blackï¼‰
uv pip install black
uv run black app/

# ç±»å‹æ£€æŸ¥ï¼ˆéœ€è¦ mypyï¼‰
uv pip install mypy
uv run mypy app/
```

### Docker Compose å‘½ä»¤

```bash
# å¯åŠ¨æœåŠ¡
docker-compose up -d

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker-compose ps

# åœæ­¢æœåŠ¡
docker-compose stop

# åœæ­¢å¹¶åˆ é™¤å®¹å™¨
docker-compose down

# é‡æ–°æ„å»ºé•œåƒ
docker-compose build --no-cache

# é‡å¯æœåŠ¡
docker-compose restart

# è¿›å…¥å®¹å™¨
docker-compose exec api bash
```

## å­¦ä¹ èµ„æº

- [FastAPI å®˜æ–¹æ–‡æ¡£](https://fastapi.tiangolo.com/)
- [FastAPI ä¸­æ–‡æ–‡æ¡£](https://fastapi.tiangolo.com/zh/)
- [Pydantic æ–‡æ¡£](https://docs.pydantic.dev/)

## è®¸å¯è¯

MIT License

## è´¡çŒ®

æ¬¢è¿æäº¤ Issue å’Œ Pull Requestï¼

